{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3217030,"sourceType":"datasetVersion","datasetId":1951218}],"dockerImageVersionId":30162,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport cv2\nimport random\nimport os\nfrom os import listdir\nfrom PIL import Image\nfrom sklearn.preprocessing import label_binarize,  LabelBinarizer\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array, array_to_img\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Flatten, Dropout, Dense\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import model_from_json\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:37.959895Z","iopub.execute_input":"2022-02-22T18:02:37.960498Z","iopub.status.idle":"2022-02-22T18:02:40.896173Z","shell.execute_reply.started":"2022-02-22T18:02:37.960431Z","shell.execute_reply":"2022-02-22T18:02:40.89536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting 12 images to check dataset\n#Now we will observe some of the iamges that are their in our dataset. We will plot 12 images here using the matplotlib library.\nplt.figure(figsize=(12,12))\npath = \"../input/leaf-image-dataset/Plant_images/Potato___Early_blight\"\nfor i in range(1,17):\n    plt.subplot(4,4,i)\n    plt.tight_layout()\n    rand_img = imread(path +'/'+ random.choice(sorted(os.listdir(path))))\n    plt.imshow(rand_img)\n    plt.xlabel(rand_img.shape[1], fontsize = 10)#width of image\n    plt.ylabel(rand_img.shape[0], fontsize = 10)#height of image","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:40.900474Z","iopub.execute_input":"2022-02-22T18:02:40.900928Z","iopub.status.idle":"2022-02-22T18:02:45.005145Z","shell.execute_reply.started":"2022-02-22T18:02:40.900894Z","shell.execute_reply":"2022-02-22T18:02:45.003917Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After visualizing the images let us move forward and create a function which will convert the images into a numpy array. It is required because we will normalize our dataset after this.","metadata":{}},{"cell_type":"code","source":"#Converting Images to array \ndef convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, (256,256))  \n            #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:45.00672Z","iopub.execute_input":"2022-02-22T18:02:45.007083Z","iopub.status.idle":"2022-02-22T18:02:45.0145Z","shell.execute_reply.started":"2022-02-22T18:02:45.007038Z","shell.execute_reply":"2022-02-22T18:02:45.013467Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dir = \"../input/leaf-image-dataset/Plant_images\"\nroot_dir = listdir(dir)\nimage_list, label_list = [], []\nall_labels = ['Corn-Common_rust', 'Potato-Early_blight', 'Tomato-Bacterial_spot']\nbinary_labels = [0,1,2]\ntemp = -1\n\n# Reading and converting image to numpy array\n#Now we will convert all the images into numpy array.\n\nfor directory in root_dir:\n  plant_image_list = listdir(f\"{dir}/{directory}\")\n  temp += 1\n  for files in plant_image_list:\n    image_path = f\"{dir}/{directory}/{files}\"\n    image_list.append(convert_image_to_array(image_path))\n    label_list.append(binary_labels[temp])\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:45.017526Z","iopub.execute_input":"2022-02-22T18:02:45.017881Z","iopub.status.idle":"2022-02-22T18:02:48.535718Z","shell.execute_reply.started":"2022-02-22T18:02:45.017818Z","shell.execute_reply":"2022-02-22T18:02:48.534797Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we will convert all the images into numpy array.\n","metadata":{}},{"cell_type":"code","source":"# Visualize the number of classes count\nlabel_counts = pd.DataFrame(label_list).value_counts()\nlabel_counts.head()\n\n#it is a balanced dataset as you can see","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:48.536971Z","iopub.execute_input":"2022-02-22T18:02:48.537372Z","iopub.status.idle":"2022-02-22T18:02:48.551829Z","shell.execute_reply.started":"2022-02-22T18:02:48.537336Z","shell.execute_reply":"2022-02-22T18:02:48.550939Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Next we will observe the shape of the image.\nimage_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:48.553281Z","iopub.execute_input":"2022-02-22T18:02:48.553985Z","iopub.status.idle":"2022-02-22T18:02:48.560088Z","shell.execute_reply.started":"2022-02-22T18:02:48.553947Z","shell.execute_reply":"2022-02-22T18:02:48.559325Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Checking the total number of the images which is the length of the labels list.\nlabel_list = np.array(label_list)\nlabel_list.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:48.561455Z","iopub.execute_input":"2022-02-22T18:02:48.561722Z","iopub.status.idle":"2022-02-22T18:02:48.579209Z","shell.execute_reply.started":"2022-02-22T18:02:48.561692Z","shell.execute_reply":"2022-02-22T18:02:48.577722Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.2, random_state = 10) ","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:48.580485Z","iopub.execute_input":"2022-02-22T18:02:48.581091Z","iopub.status.idle":"2022-02-22T18:02:48.594007Z","shell.execute_reply.started":"2022-02-22T18:02:48.581035Z","shell.execute_reply":"2022-02-22T18:02:48.593001Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Now we will normalize the dataset of our images. As pixel values ranges from 0 to 255 so we will divide each image pixel with 255 to normalize the dataset.\nx_train = np.array(x_train, dtype=np.float16) / 225.0\nx_test = np.array(x_test, dtype=np.float16) / 225.0\nx_train = x_train.reshape( -1, 256,256,3)\nx_test = x_test.reshape( -1, 256,256,3)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:48.59562Z","iopub.execute_input":"2022-02-22T18:02:48.595911Z","iopub.status.idle":"2022-02-22T18:02:52.325282Z","shell.execute_reply.started":"2022-02-22T18:02:48.595879Z","shell.execute_reply":"2022-02-22T18:02:52.324444Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:52.326906Z","iopub.execute_input":"2022-02-22T18:02:52.327198Z","iopub.status.idle":"2022-02-22T18:02:52.331865Z","shell.execute_reply.started":"2022-02-22T18:02:52.327167Z","shell.execute_reply":"2022-02-22T18:02:52.330933Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Next we will create a network architecture for the model. We have used different types of layers according to their features namely Conv_2d (It is used to create a convolutional kernel that is convolved with the input layer to produce the output tensor), max_pooling2d (It is a downsampling technique which takes out the maximum value over the window defined by poolsize), flatten (It flattens the input and creates a 1D output), Dense (Dense layer produce the output as the dot product of input and kernel).","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(256,256,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(8, activation=\"relu\"))\nmodel.add(Dense(3, activation=\"softmax\"))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:52.333296Z","iopub.execute_input":"2022-02-22T18:02:52.333541Z","iopub.status.idle":"2022-02-22T18:02:52.423334Z","shell.execute_reply.started":"2022-02-22T18:02:52.333511Z","shell.execute_reply":"2022-02-22T18:02:52.422041Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nWhile compiling the model we need to set the type of loss which will be Binary Crossentropy for our model alongwith this we also need to set the optimizer and the metrics respectively.","metadata":{}},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.0001),metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:52.425211Z","iopub.execute_input":"2022-02-22T18:02:52.426024Z","iopub.status.idle":"2022-02-22T18:02:52.442016Z","shell.execute_reply.started":"2022-02-22T18:02:52.425976Z","shell.execute_reply":"2022-02-22T18:02:52.440965Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Next we will split the dataset into validation and training data.\n# Splitting the training data set into training and validation data sets\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:52.445131Z","iopub.execute_input":"2022-02-22T18:02:52.446059Z","iopub.status.idle":"2022-02-22T18:02:52.641092Z","shell.execute_reply.started":"2022-02-22T18:02:52.446009Z","shell.execute_reply":"2022-02-22T18:02:52.639979Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training the model\nepochs = 50\nbatch_size = 128\nhistory = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, \n                    validation_data = (x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:02:52.642544Z","iopub.execute_input":"2022-02-22T18:02:52.64308Z","iopub.status.idle":"2022-02-22T18:07:39.481142Z","shell.execute_reply.started":"2022-02-22T18:02:52.64303Z","shell.execute_reply":"2022-02-22T18:07:39.479981Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plot the training history\nplt.figure(figsize=(12, 5))\nplt.plot(history.history['accuracy'], color='r')\nplt.plot(history.history['val_accuracy'], color='b')\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'val'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:07:39.485371Z","iopub.execute_input":"2022-02-22T18:07:39.485916Z","iopub.status.idle":"2022-02-22T18:07:39.726113Z","shell.execute_reply.started":"2022-02-22T18:07:39.485879Z","shell.execute_reply":"2022-02-22T18:07:39.725068Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:07:39.727492Z","iopub.execute_input":"2022-02-22T18:07:39.727808Z","iopub.status.idle":"2022-02-22T18:07:40.371861Z","shell.execute_reply.started":"2022-02-22T18:07:39.727776Z","shell.execute_reply":"2022-02-22T18:07:40.370797Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:07:40.373053Z","iopub.execute_input":"2022-02-22T18:07:40.373357Z","iopub.status.idle":"2022-02-22T18:07:41.079066Z","shell.execute_reply.started":"2022-02-22T18:07:40.373328Z","shell.execute_reply":"2022-02-22T18:07:41.078049Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting image to compare\nimg = array_to_img(x_test[10])\nimg","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:07:41.080432Z","iopub.execute_input":"2022-02-22T18:07:41.08077Z","iopub.status.idle":"2022-02-22T18:07:41.115456Z","shell.execute_reply.started":"2022-02-22T18:07:41.080735Z","shell.execute_reply":"2022-02-22T18:07:41.114802Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Finding max value from predition list and comaparing original value vs predicted\nprint(\"Originally : \",all_labels[np.argmax(y_test[10])])\nprint(\"Predicted : \",all_labels[np.argmax(y_pred[10])])","metadata":{"execution":{"iopub.status.busy":"2022-02-22T18:07:41.116483Z","iopub.execute_input":"2022-02-22T18:07:41.117069Z","iopub.status.idle":"2022-02-22T18:07:41.12363Z","shell.execute_reply.started":"2022-02-22T18:07:41.117034Z","shell.execute_reply":"2022-02-22T18:07:41.122587Z"},"trusted":true},"outputs":[],"execution_count":null}]}